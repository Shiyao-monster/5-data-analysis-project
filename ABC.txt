
import java.lang.management.ManagementFactory
import com.sun.management.OperatingSystemMXBean
import spark.implicits._
import scala.collection.JavaConverters._
import sys.process._

val procs = (1 to 1000).toDF().map(_ => {
  val hostname = "hostname".!!.trim
  val cpus = Runtime.getRuntime.availableProcessors
  val osBean = ManagementFactory.getPlatformMXBean(classOf[OperatingSystemMXBean])
  val memory = osBean.getTotalPhysicalMemorySize() / (1024 * 1024) // Memory in MB
  (hostname, cpus, memory)
}).collectAsList().asScala.toMap

val workerNodeCpus = procs.values.map(_._2).sum
val workerNodeMemory = procs.values.map(_._3).sum

println(s"Worker Node CPUs: $workerNodeCpus")
println(s"Worker Node Memory: $workerNodeMemory MB")






from pyspark.sql import SparkSession
import os

# Initialize Spark session
spark = SparkSession.builder.appName("SharedMemoryCheck").getOrCreate()

# Function to execute on worker nodes
def check_shared_memory(_):
    shm_info = os.popen("df -h /dev/shm").read()
    yield shm_info

# Create an RDD to force worker execution (the number of partitions should correspond to your worker nodes)
rdd = spark.sparkContext.parallelize(range(spark.sparkContext.defaultParallelism), spark.sparkContext.defaultParallelism)

# Run the shared memory check on each partition (worker node)
shm_info_rdd = rdd.mapPartitions(check_shared_memory).collect()

# Print the shared memory info for each worker node
for idx, shm_info in enumerate(shm_info_rdd):
    print(f"Worker {idx} shared memory info:\n{shm_info}")



import ray
import asyncio
import time

# Initialize Ray
ray.init()

class ClassA:
    def __init__(self, num_batches=500):
        self.num_batches = num_batches

    # IO-bound task (asynchronous)
    async def io_bound_task(self, batch_id):
        print(f"Starting IO-bound task for batch {batch_id}")
        await asyncio.sleep(1)  # Simulate an async IO task
        print(f"Completed IO-bound task for batch {batch_id}")
        return batch_id

    # CPU-bound task (synchronous, to be run in Ray actor)
    def cpu_bound_task(self, batch_id):
        print(f"Starting CPU-bound task for batch {batch_id}")
        time.sleep(1)  # Simulate a CPU-bound computation task
        print(f"Completed CPU-bound task for batch {batch_id}")
        return f"Batch {batch_id} processed"

    # Actor to handle CPU-bound tasks
    @ray.remote
    class CPUWorker:
        def process(self, batch_id):
            return ClassA().cpu_bound_task(batch_id)

    # Main function to process batches
    async def process_batches(self):
        # Create one IO-bound worker and seven CPU-bound workers
        cpu_workers = [self.CPUWorker.remote() for _ in range(7)]

        for batch_id in range(self.num_batches):
            # Step 1: Handle IO-bound task asynchronously
            batch_id = await self.io_bound_task(batch_id)

            # Step 2: Handle CPU-bound task using available CPU worker
            available_worker = cpu_workers[batch_id % 7]  # Select worker in a round-robin fashion
            result = await available_worker.process.remote(batch_id)

            print(ray.get(result))  # Get the result from CPU worker

# Example of running the code
if __name__ == "__main__":
    class_a = ClassA()
    asyncio.run(class_a.process_batches())




FROM databricksruntime/standard:14.3

RUN apt-get update && apt-get install -y \
    software-properties-common \
    dirmngr \
    gnupg2 \
    curl \
    build-essential \
    libssl-dev \
    zlib1g-dev \
    libbz2-dev \
    libreadline-dev \
    libsqlite3-dev \
    wget \
    libncursesw5-dev \
    libgdbm-dev \
    libc6-dev \
    liblzma-dev \
    libffi-dev \
    uuid-dev \
    libxml2-dev

RUN apt-key adv --keyserver keyserver.ubuntu.com --recv-keys E084DAB9 \
    && add-apt-repository "deb https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/"

RUN apt-get update && apt-get install -y r-base=3.6.3-1bionic

RUN add-apt-repository ppa:deadsnakes/ppa \
    && apt-get update \
    && apt-get install -y python3.8 python3.8-dev python3.8-venv

RUN update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.8 1 \
    && update-alternatives --config python3

RUN curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py \
    && python3 get-pip.py \
    && rm get-pip.py

RUN apt-get clean && rm -rf /var/lib/apt/lists/*

RUN R --version && python3 --version && pip --version
